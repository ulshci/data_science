{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '98-0.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b6df9af8da8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'98-0.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# if you want to use stopwords, here's an example of how to do this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '98-0.txt'"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('98-0.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "# stopwords = set(line.strip() for line in open('stopwords'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in stopwords:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(10):\n",
    "\tprint(word, \": \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b6df9af8da8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"“\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwordcount\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mwordcount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('98-0.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "# stopwords = set(line.strip() for line in open('stopwords'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in stopwords:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(10):\n",
    "\tprint(word, \": \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "said :  642\n",
      "mr :  616\n",
      "one :  420\n",
      "lorry :  313\n",
      "will :  290\n",
      "upon :  289\n",
      "little :  264\n",
      "man :  259\n",
      "defarge :  259\n",
      "time :  236\n"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('98-0.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "stopwords = set(line.strip() for line in open('stopwords'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in stopwords:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(10):\n",
    "\tprint(word, \": \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de :  4445\n",
      "la :  3013\n",
      "et :  2913\n",
      "le :  2493\n",
      "il :  2333\n",
      "à :  2198\n",
      "les :  1501\n",
      "un :  1432\n",
      "que :  1325\n",
      "qui :  1270\n"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('lesmiz.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "stopwords = set(line.strip() for line in open('stopwords'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in stopwords:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(10):\n",
    "\tprint(word, \": \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de :  4445\n",
      "la :  3013\n",
      "et :  2913\n",
      "le :  2493\n",
      "il :  2333\n",
      "à :  2198\n",
      "les :  1501\n",
      "un :  1432\n",
      "que :  1325\n",
      "qui :  1270\n"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('lesmiz.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "stopwords = set(line.strip() for line in open('frenchstop'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in stopwords:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(10):\n",
    "\tprint(word, \": \", count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dans :  1128\n",
      "une :  1053\n",
      "en :  1007\n",
      "des :  945\n",
      "ce :  915\n",
      "se :  858\n",
      "ne :  836\n",
      "pas :  835\n",
      "était :  778\n",
      "avait :  749\n"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('lesmiz.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "stopwords = set(line.strip() for line in open('frenchstop'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in stopwords:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(10):\n",
    "\tprint(word, \": \", count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du :  712\n",
      "je :  666\n",
      "lui :  646\n",
      "sa :  635\n",
      "son :  610\n",
      "pour :  604\n",
      "elle :  585\n",
      "vous :  577\n",
      "sur :  572\n",
      "au :  549\n"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('lesmiz.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "stopwords = set(line.strip() for line in open('frenchstop'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in stopwords:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(10):\n",
    "\tprint(word, \": \", count)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "du :  712\n",
      "je :  666\n",
      "lui :  646\n",
      "sa :  635\n",
      "son :  610\n",
      "pour :  604\n",
      "elle :  585\n",
      "vous :  577\n",
      "sur :  572\n",
      "au :  549\n",
      "cette :  549\n",
      "qu'il :  520\n",
      "plus :  502\n",
      "on :  499\n",
      "comme :  494\n",
      "tout :  493\n",
      "a :  490\n",
      "est :  460\n",
      "avec :  427\n",
      "y :  394\n",
      "par :  383\n",
      "c'est :  350\n",
      "mais :  324\n",
      "ses :  321\n",
      "nous :  298\n",
      "dit :  298\n",
      "ces :  292\n",
      "deux :  291\n",
      "bien :  273\n",
      "m :  264\n",
      "si :  262\n",
      "cela :  259\n",
      "où :  258\n",
      "me :  238\n",
      "aux :  230\n",
      "l'évêque :  230\n",
      "sans :  223\n",
      "fait :  217\n",
      "homme :  213\n",
      "même :  212\n",
      "monsieur :  211\n",
      "qu'on :  208\n",
      "d'un :  207\n",
      "madeleine :  199\n",
      "jean :  198\n",
      "c'était :  195\n",
      "d'une :  190\n",
      "fantine :  181\n",
      "valjean :  178\n",
      "là :  175\n",
      "the :  173\n",
      "peu :  173\n",
      "cet :  172\n",
      "puis :  166\n",
      "javert :  163\n",
      "été :  162\n",
      "faire :  162\n",
      "chose :  157\n",
      "quelque :  153\n",
      "quand :  152\n",
      "tous :  149\n",
      "j'ai :  149\n",
      "ou :  148\n",
      "maire :  148\n",
      "rien :  148\n",
      "sont :  146\n",
      "toute :  146\n",
      "chapitre :  144\n",
      "porte :  144\n",
      "sous :  136\n",
      "moment :  132\n",
      "être :  130\n",
      "eût :  130\n",
      "après :  127\n",
      "encore :  126\n",
      "dire :  124\n",
      "mon :  121\n",
      "l'homme :  120\n",
      "of :  119\n",
      "fut :  119\n",
      "temps :  118\n",
      "qu'elle :  117\n",
      "trois :  116\n",
      "n'avait :  114\n",
      "yeux :  114\n",
      "n'y :  114\n",
      "bon :  113\n",
      "fit :  113\n",
      "point :  110\n",
      "toutes :  110\n",
      "tête :  108\n",
      "madame :  107\n",
      "soeur :  106\n",
      "ans :  106\n",
      "femme :  106\n",
      "devant :  105\n",
      "suis :  103\n",
      "vers :  102\n",
      "moi :  102\n",
      "étaient :  102\n"
     ]
    }
   ],
   "source": [
    "# Python 3\n",
    "\n",
    "# Be sure you have followed the instructions to download the 98-0.txt,\n",
    "# the text of A Tale of Two Cities, by Charles Dickens\n",
    "\n",
    "import collections\n",
    "\n",
    "file=open('lesmiz.txt', encoding=\"utf8\")\n",
    "\n",
    "# if you want to use stopwords, here's an example of how to do this\n",
    "stopwords = set(line.strip() for line in open('frenchstop'))\n",
    "\n",
    "# create your data structure here.  F\n",
    "wordcount={}\n",
    "\n",
    "# Instantiate a dictionary, and for every word in the file, add to \n",
    "# the dictionary if it doesn't exist. If it does, increase the count.\n",
    "\n",
    "# Hint: To eliminate duplicates, remember to split by punctuation, \n",
    "# and use case demiliters. The functions lower() and split() will be useful!\n",
    "\n",
    "for word in file.read().lower().split():\n",
    "    word = word.replace(\".\",\"\")\n",
    "    word = word.replace(\",\",\"\")\n",
    "    word = word.replace(\"\\\"\",\"\")\n",
    "    word = word.replace(\"“\",\"\")\n",
    "    if word not in stopwords:\n",
    "        if word not in wordcount:\n",
    "            wordcount[word] = 1\n",
    "        else:\n",
    "            wordcount[word] += 1\n",
    "\n",
    "# after building your wordcount, you can then sort it and return the first\n",
    "# n words.  If you want, collections.Counter may be useful.\n",
    "\n",
    "d = collections.Counter(wordcount)\n",
    "\n",
    "#print(d.most_common(10))\n",
    "for word, count in d.most_common(100):\n",
    "\tprint(word, \": \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
